{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be396aa",
   "metadata": {},
   "source": [
    "# Personnaliser so modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a9289",
   "metadata": {},
   "source": [
    "Faire sa propre fonction de perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfb4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcde35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "y_train,y_test = keras.utils.to_categorical(y_train,10),keras.utils.to_categorical(y_test,10)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89391cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8c3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true,y_pred):\n",
    "    error = tf.cast(y_true, tf.float32)-y_pred\n",
    "    is_small_error = tf.abs(error)<1\n",
    "    squarred_loss = tf.square(error)/2\n",
    "    linear_loss = tf.abs(error)-0.5\n",
    "    return tf.where(is_small_error,x=squarred_loss,y=linear_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4807fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "model.compile(loss=huber_fn,optimizer=optimizer,metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.7099INFO:tensorflow:Assets written to: model_custom_loss\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_custom_loss\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0290 - accuracy: 0.7099 - val_loss: 0.0326 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0320 - accuracy: 0.6804 - val_loss: 0.0410 - val_accuracy: 0.5903 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.6205INFO:tensorflow:Assets written to: model_custom_loss\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_custom_loss\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0379 - accuracy: 0.6207 - val_loss: 0.0278 - val_accuracy: 0.7221 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0267 - accuracy: 0.7327 - val_loss: 0.0335 - val_accuracy: 0.6653 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0325 - accuracy: 0.6751 - val_loss: 0.0311 - val_accuracy: 0.6889 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0336 - accuracy: 0.6641 - val_loss: 0.0302 - val_accuracy: 0.6976 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0339 - accuracy: 0.6611 - val_loss: 0.0286 - val_accuracy: 0.7142 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0317 - accuracy: 0.6830 - val_loss: 0.0339 - val_accuracy: 0.6612 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0348 - accuracy: 0.6522 - val_loss: 0.0295 - val_accuracy: 0.7051 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0315 - accuracy: 0.6854 - val_loss: 0.0332 - val_accuracy: 0.6682 - lr: 3.8742e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x211a747c520>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "cp = keras.callbacks.ModelCheckpoint(filepath=\"model_custom_loss\",\n",
    "                                     save_best_only=True,\n",
    "                                     overwrite = True,\n",
    "                                     save_weights_only= False)\n",
    "model.fit(X_train,y_train,validation_split=0.2,epochs=10,callbacks = [lr,cp],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "091ef0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0336 - accuracy: 0.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03362317010760307, 0.6636999845504761]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b22f7d",
   "metadata": {},
   "source": [
    "Charger le model avec un élément personnalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d2b98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = keras.models.load_model(\"model_custom_loss\",\n",
    "                                       custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a95862",
   "metadata": {},
   "source": [
    "Si on veut pouvoir mettre un paramètre à notre fonction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "588ecd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber_fn(threshold=1):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = tf.cast(y_true, tf.float32)-y_pred\n",
    "        is_small_error = tf.abs(error)<threshold\n",
    "        squarred_loss = tf.square(error)/2\n",
    "        linear_loss = threshold*tf.abs(error)-threshold**2/2\n",
    "        return tf.where(is_small_error,x=squarred_loss,y=linear_loss)\n",
    "    return huber_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02742ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "model.compile(loss=create_huber_fn(2),optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "model_loaded = keras.models.load_model(\"model_custom_loss\",\n",
    "                                       custom_objects={create_huber_fn(2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6a856",
   "metadata": {},
   "source": [
    "Pour garder le threshhold enregistré lorsqu'on charge le modèle sans avoir à spécifier sa valeur quand on le load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d565cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, threshold=1,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def call(self,y_true,y_pred): # call pour losses, layers et models\n",
    "        error = tf.cast(y_true, tf.float32)-y_pred\n",
    "        is_small_error = tf.abs(error)<self.threshold\n",
    "        squarred_loss = tf.square(error)/2\n",
    "        linear_loss = self.threshold*tf.abs(error)-self.threshold**2/2\n",
    "        return tf.where(is_small_error,x=squarred_loss,y=linear_loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "model.compile(loss=HuberLoss(2),optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "model_loaded = keras.models.load_model(\"model_custom_loss\",\n",
    "                                       custom_objects={HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3e9a0",
   "metadata": {},
   "source": [
    "# Faire son propre régulariseur (ici équivalent à \"l1\") et sa propre contrainte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd46cd9",
   "metadata": {},
   "source": [
    "Régulariseur (pour ne pas avoir à spécifier la valeur du facteur de régularisation à chaque fois qu'on load le model on fait hériter de la class keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2718e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReguliser(keras.regularizers.Regularizer):\n",
    "\n",
    "    def __init__(self,factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights): # __call__ pour regularizers, initializers et constraints\n",
    "        return tf.reduce_sum(tf.abs(self.factor*weights))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {**super().get_config(), \"factor\":self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79c9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_constraint(weights):\n",
    "    return tf.where(weights<0,tf.zeros_like(weights),weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a51a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30,\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_constraint=my_constraint,\n",
    "                           kernel_regularizer=MyReguliser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba4eb1",
   "metadata": {},
   "source": [
    "On peut toujours faire la même chose: créer une classe qui hérite de keras en spécifiant la config pour ne pas avoir de pb quand on load le model et modifier la méthode __call__ pour regularizers, initializers et constraints et call pour loss, layers et models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dae82c",
   "metadata": {},
   "source": [
    "# Faire sa propre Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bff963",
   "metadata": {},
   "source": [
    "## Sans paramètres (ex: flatten ou activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965b079",
   "metadata": {},
   "source": [
    "## Avec paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,units,activation=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units #nb de neurones dans la couche dense\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    \n",
    "    def build(self, batch_input_shape):  # activé la première fois qu'on charge le modèle\n",
    "        self.kernel=self.add_weight(name=\"kernel\",shape=[batch_input_shape[-1],self.units],initializer=\"golrot_normal\")\n",
    "        self.bias = self.add_weight(name=\"bias\",shape=[self.units],initializer=\"zeros\")\n",
    "\n",
    "    def call(self,X):  # appelé pour connaître la sortie de la couche\n",
    "        return X @ self.kernel + self.bias\n",
    "    \n",
    "    def get_config(self): # utile quand on veut load le modèle sans passer les units et activation en paramètre: il les concervera automatiquement\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"units\":self.units,\"activation\":keras.activations.serialize(self.activation)}\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
