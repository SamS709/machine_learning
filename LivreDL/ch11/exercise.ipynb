{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b82a6c6",
   "metadata": {},
   "source": [
    "Crétion du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb984b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(32, 32,3)))\n",
    "for i in range(20):\n",
    "    model.add(keras.layers.Dense(100,kernel_initializer = \"he_normal\", activation = \"swish\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfd75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee96ebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb70e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2eae8e99e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee07cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06cc507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir = run_logdir,profile_batch=(100,200))\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=11)\n",
    "lr = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c8e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3535fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 20s 11ms/step - loss: 2.7739 - accuracy: 0.2112 - val_loss: 2.0000 - val_accuracy: 0.2452 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9212 - accuracy: 0.2920 - val_loss: 1.8920 - val_accuracy: 0.3187 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8631 - accuracy: 0.3181 - val_loss: 1.8761 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8326 - accuracy: 0.3355 - val_loss: 1.8283 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.8021 - accuracy: 0.3440 - val_loss: 1.8454 - val_accuracy: 0.3421 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7851 - accuracy: 0.3517 - val_loss: 1.7630 - val_accuracy: 0.3612 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.7540 - accuracy: 0.3659 - val_loss: 1.7659 - val_accuracy: 0.3554 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.7365 - accuracy: 0.3742 - val_loss: 1.7914 - val_accuracy: 0.3425 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.7136 - accuracy: 0.3859 - val_loss: 1.7228 - val_accuracy: 0.3851 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.9505 - accuracy: 0.3199 - val_loss: 1.8063 - val_accuracy: 0.3358 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 61s 49ms/step - loss: 1.7573 - accuracy: 0.3614 - val_loss: 1.7888 - val_accuracy: 0.3477 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.7271 - accuracy: 0.3753 - val_loss: 1.7736 - val_accuracy: 0.3593 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 24s 20ms/step - loss: 1.7053 - accuracy: 0.3855 - val_loss: 1.7100 - val_accuracy: 0.3857 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.6929 - accuracy: 0.3880 - val_loss: 1.7773 - val_accuracy: 0.3643 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.7987 - accuracy: 0.3330 - val_loss: 1.8407 - val_accuracy: 0.3067 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.8041 - accuracy: 0.3286 - val_loss: 1.8647 - val_accuracy: 0.3292 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7775 - accuracy: 0.3419 - val_loss: 1.7866 - val_accuracy: 0.3515 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7513 - accuracy: 0.3551 - val_loss: 1.7605 - val_accuracy: 0.3558 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6917 - accuracy: 0.3778 - val_loss: 1.7411 - val_accuracy: 0.3634 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6716 - accuracy: 0.3880 - val_loss: 1.7085 - val_accuracy: 0.3818 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6534 - accuracy: 0.3954 - val_loss: 1.7113 - val_accuracy: 0.3817 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6374 - accuracy: 0.4019 - val_loss: 1.6793 - val_accuracy: 0.3973 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6293 - accuracy: 0.4049 - val_loss: 1.6791 - val_accuracy: 0.3928 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.6129 - accuracy: 0.4115 - val_loss: 1.6589 - val_accuracy: 0.4053 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.6016 - accuracy: 0.4201 - val_loss: 1.6605 - val_accuracy: 0.4057 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5924 - accuracy: 0.4241 - val_loss: 1.6523 - val_accuracy: 0.4096 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5837 - accuracy: 0.4282 - val_loss: 1.6883 - val_accuracy: 0.3961 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5781 - accuracy: 0.4295 - val_loss: 1.6444 - val_accuracy: 0.4169 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5674 - accuracy: 0.4338 - val_loss: 1.6399 - val_accuracy: 0.4155 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.5617 - accuracy: 0.4365 - val_loss: 1.6710 - val_accuracy: 0.3957 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5572 - accuracy: 0.4404 - val_loss: 1.6869 - val_accuracy: 0.4010 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5503 - accuracy: 0.4398 - val_loss: 1.6276 - val_accuracy: 0.4206 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.5448 - accuracy: 0.4430 - val_loss: 1.6665 - val_accuracy: 0.4035 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.5399 - accuracy: 0.4470 - val_loss: 1.6228 - val_accuracy: 0.4162 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.5428 - accuracy: 0.4430 - val_loss: 1.6360 - val_accuracy: 0.4141 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.5290 - accuracy: 0.4493 - val_loss: 1.6283 - val_accuracy: 0.4230 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.5252 - accuracy: 0.4534 - val_loss: 1.6279 - val_accuracy: 0.4172 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.5171 - accuracy: 0.4563 - val_loss: 1.6298 - val_accuracy: 0.4236 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.5137 - accuracy: 0.4567 - val_loss: 1.6518 - val_accuracy: 0.4180 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4736 - accuracy: 0.4700 - val_loss: 1.6101 - val_accuracy: 0.4282 - lr: 2.5000e-04\n",
      "Epoch 41/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4637 - accuracy: 0.4737 - val_loss: 1.6141 - val_accuracy: 0.4302 - lr: 2.5000e-04\n",
      "Epoch 42/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.4574 - accuracy: 0.4750 - val_loss: 1.6288 - val_accuracy: 0.4256 - lr: 2.5000e-04\n",
      "Epoch 43/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4529 - accuracy: 0.4773 - val_loss: 1.6164 - val_accuracy: 0.4317 - lr: 2.5000e-04\n",
      "Epoch 44/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4481 - accuracy: 0.4791 - val_loss: 1.6163 - val_accuracy: 0.4337 - lr: 2.5000e-04\n",
      "Epoch 45/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4430 - accuracy: 0.4808 - val_loss: 1.6363 - val_accuracy: 0.4254 - lr: 2.5000e-04\n",
      "Epoch 46/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.4155 - accuracy: 0.4915 - val_loss: 1.6234 - val_accuracy: 0.4342 - lr: 1.2500e-04\n",
      "Epoch 47/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4083 - accuracy: 0.4937 - val_loss: 1.6132 - val_accuracy: 0.4346 - lr: 1.2500e-04\n",
      "Epoch 48/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.4030 - accuracy: 0.4946 - val_loss: 1.6220 - val_accuracy: 0.4271 - lr: 1.2500e-04\n",
      "Epoch 49/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 1.3984 - accuracy: 0.4963 - val_loss: 1.6207 - val_accuracy: 0.4359 - lr: 1.2500e-04\n",
      "Epoch 50/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.3951 - accuracy: 0.4971 - val_loss: 1.6234 - val_accuracy: 0.4310 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,validation_split=0.2,epochs=50,callbacks=[tensorboard_cb,early_stopping_cb,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f88cc1",
   "metadata": {},
   "source": [
    "AVEC BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "366b5b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 35s 17ms/step - loss: 1.9923 - accuracy: 0.2738 - val_loss: 2.0049 - val_accuracy: 0.3034 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.7542 - accuracy: 0.3696 - val_loss: 1.8669 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.6654 - accuracy: 0.4025 - val_loss: 1.8274 - val_accuracy: 0.3609 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.6093 - accuracy: 0.4288 - val_loss: 1.7569 - val_accuracy: 0.3865 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.5617 - accuracy: 0.4459 - val_loss: 1.9418 - val_accuracy: 0.3442 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.5108 - accuracy: 0.4672 - val_loss: 1.6102 - val_accuracy: 0.4262 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.4690 - accuracy: 0.4809 - val_loss: 1.6230 - val_accuracy: 0.4165 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.4362 - accuracy: 0.4924 - val_loss: 1.5984 - val_accuracy: 0.4252 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.4013 - accuracy: 0.5051 - val_loss: 1.4882 - val_accuracy: 0.4753 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.3626 - accuracy: 0.5178 - val_loss: 1.5839 - val_accuracy: 0.4432 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.3313 - accuracy: 0.5315 - val_loss: 1.7858 - val_accuracy: 0.3934 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.3041 - accuracy: 0.5389 - val_loss: 1.6200 - val_accuracy: 0.4518 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.2767 - accuracy: 0.5512 - val_loss: 1.6442 - val_accuracy: 0.4368 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.2486 - accuracy: 0.5594 - val_loss: 1.5519 - val_accuracy: 0.4658 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.1531 - accuracy: 0.5943 - val_loss: 1.3983 - val_accuracy: 0.5185 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.1215 - accuracy: 0.6045 - val_loss: 1.3701 - val_accuracy: 0.5260 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.1017 - accuracy: 0.6111 - val_loss: 1.4355 - val_accuracy: 0.5057 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0849 - accuracy: 0.6161 - val_loss: 1.4393 - val_accuracy: 0.5017 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.0705 - accuracy: 0.6220 - val_loss: 1.4890 - val_accuracy: 0.4965 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.0511 - accuracy: 0.6305 - val_loss: 1.4881 - val_accuracy: 0.4962 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0391 - accuracy: 0.6331 - val_loss: 1.4929 - val_accuracy: 0.5056 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9687 - accuracy: 0.6555 - val_loss: 1.4021 - val_accuracy: 0.5292 - lr: 2.5000e-04\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9565 - accuracy: 0.6610 - val_loss: 1.5516 - val_accuracy: 0.5010 - lr: 2.5000e-04\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9439 - accuracy: 0.6650 - val_loss: 1.3997 - val_accuracy: 0.5333 - lr: 2.5000e-04\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9365 - accuracy: 0.6679 - val_loss: 1.4520 - val_accuracy: 0.5095 - lr: 2.5000e-04\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9290 - accuracy: 0.6703 - val_loss: 1.4592 - val_accuracy: 0.5181 - lr: 2.5000e-04\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.8963 - accuracy: 0.6821 - val_loss: 1.4075 - val_accuracy: 0.5356 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Flatten(input_shape=(32, 32,3)))\n",
    "for i in range(19):\n",
    "    model1.add(keras.layers.Dense(100,kernel_initializer = \"he_normal\"))\n",
    "    model1.add(keras.layers.BatchNormalization())\n",
    "    model1.add(keras.layers.Activation(\"swish\"))\n",
    "model1.add(keras.layers.Dense(100,kernel_initializer = \"he_normal\"))\n",
    "model1.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir = run_logdir,profile_batch=(100,200))\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=11)\n",
    "lr = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience = 5)\n",
    "\n",
    "model1.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history1 = model1.fit(X_train,y_train,validation_split=0.2,epochs=50,callbacks=[tensorboard_cb,early_stopping_cb,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2026ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 23s 13ms/step - loss: 1.8360 - accuracy: 0.3463 - val_loss: 1.7253 - val_accuracy: 0.3872 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.6188 - accuracy: 0.4196 - val_loss: 1.6167 - val_accuracy: 0.4308 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5228 - accuracy: 0.4567 - val_loss: 1.5783 - val_accuracy: 0.4472 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4481 - accuracy: 0.4873 - val_loss: 1.5426 - val_accuracy: 0.4572 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.3870 - accuracy: 0.5064 - val_loss: 1.5419 - val_accuracy: 0.4579 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3326 - accuracy: 0.5253 - val_loss: 1.5017 - val_accuracy: 0.4691 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.2781 - accuracy: 0.5446 - val_loss: 1.5096 - val_accuracy: 0.4732 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.2328 - accuracy: 0.5621 - val_loss: 1.4840 - val_accuracy: 0.4802 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.1863 - accuracy: 0.5778 - val_loss: 1.5133 - val_accuracy: 0.4776 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.1440 - accuracy: 0.5931 - val_loss: 1.4926 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.1065 - accuracy: 0.6071 - val_loss: 1.5063 - val_accuracy: 0.4870 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.0648 - accuracy: 0.6248 - val_loss: 1.5492 - val_accuracy: 0.4853 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.0295 - accuracy: 0.6350 - val_loss: 1.5314 - val_accuracy: 0.5009 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.9021 - accuracy: 0.6822 - val_loss: 1.5622 - val_accuracy: 0.5008 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8598 - accuracy: 0.6982 - val_loss: 1.5840 - val_accuracy: 0.4967 - lr: 5.0000e-05\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 0.8272 - accuracy: 0.7080 - val_loss: 1.6308 - val_accuracy: 0.5013 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 0.7974 - accuracy: 0.7204 - val_loss: 1.6604 - val_accuracy: 0.4979 - lr: 5.0000e-05\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 0.7680 - accuracy: 0.7320 - val_loss: 1.6896 - val_accuracy: 0.4945 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6838 - accuracy: 0.7662 - val_loss: 1.7197 - val_accuracy: 0.4989 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.Flatten(input_shape=(32, 32,3)))\n",
    "for i in range(20):\n",
    "    model2.add(keras.layers.Dense(100,kernel_initializer = \"lecun_normal\",activation=\"selu\"))\n",
    "model2.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir = run_logdir,profile_batch=(100,200))\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.0001)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=11)\n",
    "lr = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience = 5)\n",
    "\n",
    "\n",
    "model2.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "history1 = model2.fit(X_train_scaled,y_train,validation_split=0.2,epochs=50,callbacks=[early_stopping_cb,lr,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddaa8ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.9809 - accuracy: 0.3032INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 21s 12ms/step - loss: 1.9808 - accuracy: 0.3033 - val_loss: 1.7723 - val_accuracy: 0.3839 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.6859 - accuracy: 0.4020INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.6851 - accuracy: 0.4022 - val_loss: 1.6296 - val_accuracy: 0.4257 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5633 - accuracy: 0.4457INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.5631 - accuracy: 0.4460 - val_loss: 1.5840 - val_accuracy: 0.4421 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.4833 - accuracy: 0.4708INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.4833 - accuracy: 0.4708 - val_loss: 1.5744 - val_accuracy: 0.4603 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.4177 - accuracy: 0.4945INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.4176 - accuracy: 0.4944 - val_loss: 1.5323 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.3579 - accuracy: 0.5172 - val_loss: 1.5408 - val_accuracy: 0.4788 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.3030 - accuracy: 0.5360INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3036 - accuracy: 0.5358 - val_loss: 1.5304 - val_accuracy: 0.4742 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.2593 - accuracy: 0.5498INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model.x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2591 - accuracy: 0.5499 - val_loss: 1.5253 - val_accuracy: 0.4911 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.2072 - accuracy: 0.5694 - val_loss: 1.5743 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.1667 - accuracy: 0.5823 - val_loss: 1.5964 - val_accuracy: 0.4881 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1296 - accuracy: 0.5948 - val_loss: 1.6154 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.0879 - accuracy: 0.6112 - val_loss: 1.6036 - val_accuracy: 0.4952 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 1.0506 - accuracy: 0.6250 - val_loss: 1.6637 - val_accuracy: 0.4935 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.9368 - accuracy: 0.6647 - val_loss: 1.7101 - val_accuracy: 0.5000 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.8972 - accuracy: 0.6805 - val_loss: 1.7666 - val_accuracy: 0.5021 - lr: 5.0000e-05\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.8667 - accuracy: 0.6897 - val_loss: 1.8020 - val_accuracy: 0.4997 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.8351 - accuracy: 0.7002 - val_loss: 1.8418 - val_accuracy: 0.4888 - lr: 5.0000e-05\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.8094 - accuracy: 0.7099 - val_loss: 1.9397 - val_accuracy: 0.4952 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.7338 - accuracy: 0.7366 - val_loss: 1.9932 - val_accuracy: 0.4963 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import AlphaDropout\n",
    "\n",
    "model3 = keras.models.Sequential()\n",
    "model3.add(keras.layers.Flatten(input_shape=(32, 32,3)))\n",
    "for i in range(20):\n",
    "    model3.add(keras.layers.Dense(100,kernel_initializer = \"lecun_normal\",activation=\"selu\"))\n",
    "model3.add(AlphaDropout(rate=0.1))\n",
    "model3.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir = run_logdir,profile_batch=(100,200))\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.0001)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=11)\n",
    "lr = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience = 5)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.x\", save_best_only=True)\n",
    "\n",
    "\n",
    "model3.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "history3 = model3.fit(X_train_scaled,y_train,validation_split=0.2,epochs=50,callbacks=[early_stopping_cb,lr,tensorboard_cb,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528524d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efdc38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.models.clone_model(model3)\n",
    "model4.set_weights(model3.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7843c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_probas = np.stack([model4(X_test_scaled,training = True) for sample in range(100)])\n",
    "print(y_probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4063177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4958\n",
      "0.4972\n",
      "[3 8 8 ... 3 5 7]\n",
      "[3 8 8 ... 5 1 7]\n",
      "y_pred_MC[0] =  3\n",
      "y_std_MC[0] =  [0.00128662 0.00290014 0.00174352 0.04871127 0.02121467 0.04483201\n",
      " 0.00104317 0.00237533 0.01042468 0.00327799]\n",
      "y_pred[0] =  3\n"
     ]
    }
   ],
   "source": [
    "y_pred_MC = np.mean(y_probas,axis=0)\n",
    "y_std_MC_class = np.std(y_probas,axis=0)\n",
    "y_pred_class = model4(X_test_scaled,training = False)\n",
    "y_pred_MC = np.argmax(y_std_MC_class,axis=1)\n",
    "y_pred = np.argmax(y_pred_class,axis=1)\n",
    "accuracy_MC = np.mean([y_pred_MC==y_test.flatten()])\n",
    "accuracy = np.mean([y_pred==y_test.flatten()])\n",
    "print(accuracy_MC)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "print(y_pred_MC)\n",
    "print(y_test.flatten())\n",
    "print(\"y_pred_MC[0] = \",y_pred_MC[0])\n",
    "print(\"y_std_MC[0] = \",y_std_MC_class[0])\n",
    "print(\"y_pred[0] = \",y_pred[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
